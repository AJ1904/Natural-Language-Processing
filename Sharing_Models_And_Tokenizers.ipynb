{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlpKqtZW6ZWB"
      },
      "source": [
        "# Using pretrained models (PyTorch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kl3Siq0d6ZWD"
      },
      "source": [
        "Install the Transformers, Datasets, and Evaluate libraries to run this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZCH4tzaL6ZWD"
      },
      "outputs": [],
      "source": [
        "!pip install datasets evaluate transformers[sentencepiece]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using pretrained models from the Model Hub is straightforward and highly convenient. Let's break down how to select, load, and use a model, ensuring it aligns with the intended task.\n",
        "\n",
        "### Selecting and Loading a Model\n",
        "\n",
        "1. **Selecting a Model:**\n",
        "\n",
        "  This retrieves the camembert-base checkpoint to fill masked tokens.\n",
        "\n",
        "2. **Using the Model:**\n",
        "\n",
        "   This code uses the model to predict masked tokens in the given sequence."
      ],
      "metadata": {
        "id": "yfsUJkZx6tZ_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_WcGccH6ZWD",
        "outputId": "80e39973-c146-42b5-99cd-0fc5155e75c2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[\n",
              "  {'sequence': 'Le camembert est délicieux :)', 'score': 0.49091005325317383, 'token': 7200, 'token_str': 'délicieux'}, \n",
              "  {'sequence': 'Le camembert est excellent :)', 'score': 0.1055697426199913, 'token': 2183, 'token_str': 'excellent'}, \n",
              "  {'sequence': 'Le camembert est succulent :)', 'score': 0.03453313186764717, 'token': 26202, 'token_str': 'succulent'}, \n",
              "  {'sequence': 'Le camembert est meilleur :)', 'score': 0.0330314114689827, 'token': 528, 'token_str': 'meilleur'}, \n",
              "  {'sequence': 'Le camembert est parfait :)', 'score': 0.03007650189101696, 'token': 1654, 'token_str': 'parfait'}\n",
              "]"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "camembert_fill_mask = pipeline(\"fill-mask\", model=\"camembert-base\")\n",
        "results = camembert_fill_mask(\"Le camembert est <mask> :)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### Choosing the Right Checkpoint\n",
        "\n",
        "- Ensure the checkpoint chosen aligns with the task. Loading a checkpoint meant for one task into another pipeline may yield nonsensical results. Utilize the task selector in the Hugging Face Hub interface for appropriate checkpoint selection.\n",
        "\n",
        "### Alternative Loading Methods\n",
        "\n",
        "- **Using Specific Architecture:**\n",
        "  \n",
        "   This method restricts users to checkpoints compatible with the CamemBERT architecture.\n",
        "\n"
      ],
      "metadata": {
        "id": "BfBPK-B-6zOK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vOybhRsN6ZWE"
      },
      "outputs": [],
      "source": [
        "from transformers import CamembertTokenizer, CamembertForMaskedLM\n",
        "\n",
        "tokenizer = CamembertTokenizer.from_pretrained(\"camembert-base\")\n",
        "model = CamembertForMaskedLM.from_pretrained(\"camembert-base\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Using Auto* Classes:**\n",
        "   \n",
        "   Utilizing Auto* classes allows easy checkpoint switching as they are architecture-agnostic.\n"
      ],
      "metadata": {
        "id": "JhvXj3jv7BnL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SbSsbqid6ZWE"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"camembert-base\")\n",
        "model = AutoModelForMaskedLM.from_pretrained(\"camembert-base\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pretrained Model Considerations\n",
        "\n",
        "- Check how the model was trained, its training datasets, limitations, and biases via its model card. Understanding these aspects is crucial before utilizing a pretrained model.\n",
        "\n",
        "Utilizing pretrained models simplifies access to powerful models but demands caution in selecting the appropriate checkpoint for the intended task and understanding its limitations and biases."
      ],
      "metadata": {
        "id": "cbPK6Rzs7H3T"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l4WIjtBw7PkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfDAcosD7NKo"
      },
      "source": [
        "# Sharing pretrained models (PyTorch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-jSy50w7NKp"
      },
      "source": [
        "You will need to setup git, adapt your email and name in the following cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "my59wlAf7NKq"
      },
      "outputs": [],
      "source": [
        "!git config --global user.email \"abcd@example.com\"\n",
        "!git config --global user.name \"ABCD\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2tNtn7i7NKq"
      },
      "source": [
        "You will also need to be logged in to the Hugging Face Hub. Execute the following and enter your credentials."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aFq4B0jC7NKq"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qVUUvXH97NKq"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4bxeVpUG7NKq"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    \"bert-finetuned-mrpc\", save_strategy=\"epoch\", push_to_hub=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7hxNH49S7NKq"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
        "\n",
        "checkpoint = \"camembert-base\"\n",
        "\n",
        "model = AutoModelForMaskedLM.from_pretrained(checkpoint)\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yOYfkToM7NKq"
      },
      "outputs": [],
      "source": [
        "model.push_to_hub(\"dummy-model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8z-p1Y0O7NKq"
      },
      "outputs": [],
      "source": [
        "tokenizer.push_to_hub(\"dummy-model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YkaUu1BA7NKq"
      },
      "outputs": [],
      "source": [
        "tokenizer.push_to_hub(\"dummy-model\", organization=\"huggingface\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxSjG_747NKr"
      },
      "outputs": [],
      "source": [
        "tokenizer.push_to_hub(\"dummy-model\", organization=\"huggingface\", use_auth_token=\"<TOKEN>\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-NeTBEy7NKr"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import (\n",
        "    # User management\n",
        "    login,\n",
        "    logout,\n",
        "    whoami,\n",
        "\n",
        "    # Repository creation and management\n",
        "    create_repo,\n",
        "    delete_repo,\n",
        "    update_repo_visibility,\n",
        "\n",
        "    # And some methods to retrieve/change information about the content\n",
        "    list_models,\n",
        "    list_datasets,\n",
        "    list_metrics,\n",
        "    list_repo_files,\n",
        "    upload_file,\n",
        "    delete_file,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L6ppgYxk7NKr"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import create_repo\n",
        "\n",
        "create_repo(\"dummy-model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xBlr4gFY7NKr"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import create_repo\n",
        "\n",
        "create_repo(\"dummy-model\", organization=\"huggingface\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kXaqQ3qt7NKr"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import upload_file\n",
        "\n",
        "upload_file(\n",
        "    \"<path_to_file>/config.json\",\n",
        "    path_in_repo=\"config.json\",\n",
        "    repo_id=\"<namespace>/dummy-model\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LzzKw6Bi7NKr"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import Repository\n",
        "\n",
        "repo = Repository(\"<path_to_dummy_folder>\", clone_from=\"<namespace>/dummy-model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t8KGbSII7NKr"
      },
      "outputs": [],
      "source": [
        "repo.git_pull()\n",
        "repo.git_add()\n",
        "repo.git_commit()\n",
        "repo.git_push()\n",
        "repo.git_tag()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "044X1YzP7NKr"
      },
      "outputs": [],
      "source": [
        "repo.git_pull()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H9kEC0JL7NKr"
      },
      "outputs": [],
      "source": [
        "model.save_pretrained(\"<path_to_dummy_folder>\")\n",
        "tokenizer.save_pretrained(\"<path_to_dummy_folder>\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QEpd_NxX7NKr"
      },
      "outputs": [],
      "source": [
        "repo.git_add()\n",
        "repo.git_commit(\"Add model and tokenizer files\")\n",
        "repo.git_push()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wCOkCN3s7NKr"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
        "\n",
        "checkpoint = \"camembert-base\"\n",
        "\n",
        "model = AutoModelForMaskedLM.from_pretrained(checkpoint)\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "\n",
        "# Do whatever with the model, train it, fine-tune it...\n",
        "\n",
        "model.save_pretrained(\"<path_to_dummy_folder>\")\n",
        "tokenizer.save_pretrained(\"<path_to_dummy_folder>\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yT46_Eei7i2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building a Model Card"
      ],
      "metadata": {
        "id": "fJ8w4Ah67mE7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a model card is an essential step in documenting your model's details, intended use cases, limitations, training process, and evaluation results. Here's an overview of what each section should contain:\n",
        "\n",
        "### Model Description\n",
        "- Basic information about the model, including architecture, version, paper reference, author details, and copyright.\n",
        "- General insights into training procedures, parameters, and important disclaimers.\n",
        "\n",
        "### Intended Uses & Limitations\n",
        "- Description of the use cases where the model is intended to be applied, including languages, fields, and domains.\n",
        "- Document any known limitations or areas where the model might perform suboptimally.\n",
        "\n",
        "### How to Use\n",
        "- Examples demonstrating how to use the model, showcasing usage of pipeline(), model, and tokenizer classes, and other helpful code snippets.\n",
        "\n",
        "### Training Data\n",
        "- Indication of the dataset(s) used for training, along with a brief description of the dataset(s).\n",
        "\n",
        "### Training Procedure\n",
        "- Detailed information on training aspects, including preprocessing, postprocessing, number of epochs, batch size, learning rate, and other relevant details for reproducibility.\n",
        "\n",
        "### Variables and Metrics\n",
        "- Description of evaluation metrics used, factors measured, and details on which metrics were used on specific datasets or dataset splits.\n",
        "\n",
        "### Evaluation Results\n",
        "- An overview of the model's performance on the evaluation dataset, including any decision thresholds used in evaluation.\n",
        "\n",
        "### Example Model Cards\n",
        "- Check well-crafted model cards like `bert-base-cased`, `gpt2`, `distilbert`, and explore examples from various organizations and companies.\n",
        "\n",
        "### Model Card Metadata\n",
        "- Model metadata in the model card header, including language, license, datasets used, and other specifications, helps categorize the model on platforms like the Hugging Face Hub.\n",
        "\n",
        "Documenting these sections in your model card enhances the model's accessibility, reproducibility, and understanding for future users. While not mandatory, providing comprehensive documentation greatly benefits the community using your model."
      ],
      "metadata": {
        "id": "Vd2kpO417j1A"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}